#!/usr/local/env groovy
/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
*
* Jenkinsfile for building rapids-plugin
*
*/
@Library(['shared-libs', 'spark-jenkins-shared-lib']) _

def urmUrl="https://${ArtifactoryConstants.ARTIFACTORY_NAME}/artifactory/sw-spark-maven"

pipeline {
    agent { label 'vanilla' }

    options {
        ansiColor('xterm')
        timeout(time: 300, unit: 'MINUTES') // should be larger than integration timeout (240 minutes)
        buildDiscarder(logRotator(numToKeepStr: '10'))
        parallelsAlwaysFailFast()
    }

    parameters {
        string(name: 'REF', defaultValue: 'branch-0.3', description: 'Commit to build')
    }

    environment {
        JENKINS_ROOT  = 'jenkins'
        MVN_URM_MIRROR='-s jenkins/settings.xml -P mirror-apache-to-urm'
        LIBCUDF_KERNEL_CACHE_PATH='/tmp/.cudf'
        URM_CREDS = credentials("svcngcc_artifactory")
        ARTIFACTORY_NAME = "${ArtifactoryConstants.ARTIFACTORY_NAME}"
        URM_URL = "${urmUrl}"
    }

    triggers {
        cron('H 10 * * *') // 10am PDT
    }

    stages {
        stage('Ubuntu16 CUDA10.1') {
            agent { label 'docker-gpu' }
            steps {
                script {
                    def CUDA_NAME=sh(returnStdout: true,
                        script: '. jenkins/version-def.sh>&2 && echo -n $CUDA_CLASSIFIER | sed "s/-/./g"')
                    def IMAGE_NAME="$ARTIFACTORY_NAME/sw-spark-docker/plugin:dev-ubuntu16-$CUDA_NAME"
                    def CUDA_VER="$CUDA_NAME" - "cuda"
                    sh "docker pull $IMAGE_NAME"
                    def urmImageID=sh(returnStdout: true, script: "docker inspect -f {{'.Id'}} $IMAGE_NAME")
                    // Speed up Docker building via '--cache-from $IMAGE_NAME'
                    def buildImage=docker.build(IMAGE_NAME,
                        "-f jenkins/Dockerfile.ubuntu16 --build-arg CUDA_VER=$CUDA_VER --cache-from $IMAGE_NAME -t $IMAGE_NAME .")
                    def buildImageID=sh(returnStdout: true, script: "docker inspect -f {{'.Id'}} $IMAGE_NAME")
                    if (! buildImageID.equals(urmImageID)) {
                        echo "Dockerfile updated, upload docker image to URM"
                        uploadDocker(IMAGE_NAME)
                    }

                    buildImage.inside("--runtime=nvidia \
                        -v ${HOME}/.zinc:${HOME}/.zinc:rw") {
                        sh "jenkins/spark-nightly-build.sh"
                    }
                }
            }
        } // end of Ubuntu16 CUDA10.1

        stage('Trigger integration tests') {
            when {
                beforeAgent true
                expression { currentBuild.currentResult == "SUCCESS" }
            }

            parallel {
                stage('trigger integration test for spark-3.0.0') {
                    steps {
                        build(job: 'spark/rapids_integration-0.3-github',
                                propagate: false,
                                parameters: [string(name: 'REF', value: 'branch-0.3')])
                    }
                }

                stage('trigger integration test for spark-3.0.1') {
                    steps {
                        build(job: 'spark/rapids_integration-3.0.1-0.3-github',
                                propagate: false,
                                parameters: [string(name: 'REF', value: 'branch-0.3')])
                    }
                }
            }
        } // end of Trigger integration tests
    } // end of stages

    post {
        always {
            script {
                if (currentBuild.currentResult == "SUCCESS") {
                    slack("#swrapids-spark-cicd", "Success", color: "#33CC33")
                } else {
                    slack("#swrapids-spark-cicd", "Failed", color: "#FF0000")
                }
            }
        }
    }
} // end of pipeline

void uploadDocker(String IMAGE_NAME) {
    def DOCKER_CMD="docker --config $WORKSPACE/.docker"
    sh """
        echo $URM_CREDS_PSW | $DOCKER_CMD login $ARTIFACTORY_NAME -u $URM_CREDS_USR --password-stdin
        $DOCKER_CMD push $IMAGE_NAME
        $DOCKER_CMD logout $ARTIFACTORY_NAME
    """
}

void slack(Map params = [:], String channel, String message) {
    Map defaultParams = [
            color: "#000000",
            baseUrl: "${SparkConstants.SLACK_API_ENDPOINT}",
            tokenCredentialId: "slack_token"
    ]

    params["channel"] = channel
    params["message"] = "${BUILD_URL}\n" + message

    slackSend(defaultParams << params)
}
