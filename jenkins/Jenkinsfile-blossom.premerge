#!/usr/local/env groovy
/*
 * Copyright (c) 2020-2021, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 *
 * Jenkinsfile for building rapids-plugin on blossom
 *
 */

@Library(['shared-libs', 'blossom-lib']) _
@Library('blossom-github-lib@master')
import ipp.blossom.*

def githubHelper // blossom github helper
def TEMP_IMAGE_BUILD = true
def CUDA_NAME = 'cuda11.0' // hardcode cuda version for docker build part
def PREMERGE_DOCKERFILE = 'jenkins/Dockerfile-blossom.ubuntu'
def IMAGE_PREMERGE // temp image for premerge test
def PREMERGE_TAG
def skipped = false
def PROJECT_VER // project version retrieved from 'version-def.sh' to determine compatible stages
def major_ver // major version extracted from project version
def minor_ver // minor version extracted from project version
def PREMERGE_CI_2_ARGUMENT // argument for 'spark-premerge-build.sh' running from stage of Premerge CI 2

pipeline {
    agent {
        kubernetes {
            label "premerge-init-${BUILD_TAG}"
            cloud 'sc-ipp-blossom-prod'
        }
    }

    options {
        ansiColor('xterm')
        buildDiscarder(logRotator(numToKeepStr: '50'))
        skipDefaultCheckout true
        // TODO: improve resource management
        timeout(time: 12, unit: 'HOURS') // long enough to make sure we won't timeout GPU scheduling w/ too many concurrent builds
    }

    environment {
        JENKINS_ROOT = 'jenkins'
        PREMERGE_SCRIPT = '$JENKINS_ROOT/spark-premerge-build.sh'
        MVN_URM_MIRROR = '-s jenkins/settings.xml -P mirror-apache-to-urm'
        LIBCUDF_KERNEL_CACHE_PATH = '/tmp/.cudf'
        ARTIFACTORY_NAME = "${ArtifactoryConstants.ARTIFACTORY_NAME}"
        GITHUB_TOKEN = credentials("github-token")
        URM_CREDS = credentials("urm_creds")
        URM_URL = "https://${ArtifactoryConstants.ARTIFACTORY_NAME}/artifactory/sw-spark-maven"
        PVC = credentials("pvc")
        CUSTOM_WORKSPACE = "/home/jenkins/agent/workspace/${BUILD_TAG}"
        CUDA_CLASSIFIER = 'cuda11'
    }

    stages {
        stage("Init githubHelper") {
            steps {
                script {
                    githubHelper = GithubHelper.getInstance("${GITHUB_TOKEN}", githubData)
                    githubHelper.updateCommitStatus("$BUILD_URL", "Running", GitHubCommitState.PENDING)

                    def title = githubHelper.getIssue().title
                    if (title ==~ /.*\[skip ci\].*/) {
                        githubHelper.updateCommitStatus("$BUILD_URL", "Skipped", GitHubCommitState.SUCCESS)
                        currentBuild.result == "SUCCESS"
                        skipped = true
                        return
                    }
                }
            }
        } // end of Init githubHelper

        stage('Build docker image') {
            when {
                beforeAgent true
                expression {
                    !skipped
                }
            }

            agent {
                kubernetes {
                    label "premerge-docker-${BUILD_TAG}"
                    cloud 'sc-ipp-blossom-prod'
                    yaml pod.getDockerBuildYAML()
                    workspaceVolume persistentVolumeClaimWorkspaceVolume(claimName: "${PVC}", readOnly: false)
                    customWorkspace "${CUSTOM_WORKSPACE}"
                }
            }

            steps {
                script {
                    currentBuild.description = githubHelper.getBuildDescription()
                    checkout(
                            changelog: false,
                            poll: true,
                            scm: [
                                    $class: 'GitSCM', branches: [[name: githubHelper.getMergedSHA()]],
                                    doGenerateSubmoduleConfigurations: false,
                                    submoduleCfg: [],
                                    userRemoteConfigs: [[
                                        credentialsId: 'github-token',
                                        url: githubHelper.getCloneUrl(),
                                        refspec: '+refs/pull/*/merge:refs/remotes/origin/pr/*']]
                            ]
                    )

                    stash(name: "source_tree", includes: "**")

                    container('docker-build') {
                        // check if pre-merge dockerfile modified
                        def dockerfileModified = sh(returnStdout: true,
                                script: 'BASE=$(git --no-pager log --oneline -1 | awk \'{ print $NF }\'); ' +
                                        'git --no-pager diff --name-only HEAD $(git merge-base HEAD $BASE) ' +
                                        "-- ${PREMERGE_DOCKERFILE} || true")
                        if (!dockerfileModified?.trim()) {
                            TEMP_IMAGE_BUILD = false
                        }

                        if (TEMP_IMAGE_BUILD) {
                            IMAGE_TAG = "dev-ubuntu18-${CUDA_NAME}"
                            PREMERGE_TAG = "${IMAGE_TAG}-${BUILD_TAG}"
                            IMAGE_PREMERGE = "${ARTIFACTORY_NAME}/sw-spark-docker-local/plugin:${PREMERGE_TAG}"
                            def CUDA_VER = "$CUDA_NAME" - "cuda"
                            docker.build(IMAGE_PREMERGE, "-f ${PREMERGE_DOCKERFILE} --build-arg CUDA_VER=$CUDA_VER -t $IMAGE_PREMERGE .")
                            uploadDocker(IMAGE_PREMERGE)
                        } else {
                            // if no pre-merge dockerfile change, use nightly image
                            IMAGE_PREMERGE = "$ARTIFACTORY_NAME/sw-spark-docker-local/plugin:dev-ubuntu18-$CUDA_NAME-blossom-dev"
                        }
                    }
                }
            }
        } // end of Build docker image

        stage("Determine Project Version") {
            when {
                expression {
                    !skipped
                }
            }

            steps {
                script {
                    unstash "source_tree"
                    // Retrieve PROJECT_VER from version-def.sh, e.g, '21.10.0-SNAPSHOT'
                    PROJECT_VER = sh(returnStdout: true, script: "bash $JENKINS_ROOT/version-def.sh | cut -d ',' -f 3 | cut -d ' ' -f 3")
                    PROJECT_VER = PROJECT_VER.split('-')[0] // Remove trailing '-SNAPSHOT'
                    echo PROJECT_VER

                    def versions = PROJECT_VER.split('\\.')
                    major_ver = versions[0].toInteger()
                    minor_ver = versions[1].toInteger()

                    if (major_ver >= 21) {
                        if (minor_ver == 8) {
                            PREMERGE_CI_2_ARGUMENT = "unit_test" // for '21.08' version
                        } else if (minor_ver >= 10) {
                            PREMERGE_CI_2_ARGUMENT = "ci_2" // for '21.10' or later version
                        } else {
                            // do nothing to avoid breaking old version
                        }
                    } else {
                        error("Unsupported major version: $major_ver")
                    }

                    echo PREMERGE_CI_2_ARGUMENT
                }
            }
        }

        stage('Premerge Test') {
            when {
                beforeAgent true
                beforeOptions true
                expression {
                    !skipped
                }
            }

            // Parallel run mvn verify (build and integration tests) and unit tests (for multiple Spark versions)
            // If any one is failed will abort another if not finish yet and will upload failure log to Github
            failFast true
            parallel {
                stage('mvn verify') {
                    options {
                        // We have to use params to pass the resource label in options block,
                        // this is a limitation of declarative pipeline. And we need to lock resource before agent start
                        lock(label: "${params.GPU_POOL}", quantity: 1, variable: 'GPU_RESOURCE')
                    }
                    agent {
                        kubernetes {
                            label "premerge-ci-1-${BUILD_TAG}"
                            cloud 'sc-ipp-blossom-prod'
                            yaml pod.getGPUYAML("${IMAGE_PREMERGE}", "${env.GPU_RESOURCE}", '8', '32Gi') // cpu: 8, memory: 32Gi
                            workspaceVolume persistentVolumeClaimWorkspaceVolume(claimName: "${PVC}", readOnly: false)
                            customWorkspace "${CUSTOM_WORKSPACE}"
                        }
                    }

                    steps {
                        script {
                            container('gpu') {
                                timeout(time: 4, unit: 'HOURS') { // step only timeout for test run
                                    sh "$PREMERGE_SCRIPT mvn_verify"
                                    step([$class                : 'JacocoPublisher',
                                          execPattern           : '**/target/jacoco.exec',
                                          classPattern          : 'target/jacoco_classes/',
                                          sourcePattern         : 'shuffle-plugin/src/main/scala/,udf-compiler/src/main/scala/,sql-plugin/src/main/java/,sql-plugin/src/main/scala/,shims/spark311/src/main/scala/,shims/spark301db/src/main/scala/,shims/spark301/src/main/scala/,shims/spark302/src/main/scala/,shims/spark303/src/main/scala/,shims/spark304/src/main/scala/,shims/spark312/src/main/scala/,shims/spark313/src/main/scala/',
                                          sourceInclusionPattern: '**/*.java,**/*.scala'
                                    ])
                                }
                            }
                        }
                    }
                } // end of mvn verify stage

                stage('Premerge CI 2') {
                    when {
                        beforeAgent true
                        beforeOptions true
                        expression {
                            major_ver >= 21 && minor_ver >= 8
                        }
                    }

                    options {
                        // We have to use params to pass the resource label in options block,
                        // this is a limitation of declarative pipeline. And we need to lock resource before agent start
                        lock(label: "${params.GPU_POOL}", quantity: 1, variable: 'GPU_RESOURCE')
                    }
                    agent {
                        kubernetes {
                            label "premerge-ci-2-${BUILD_TAG}"
                            cloud 'sc-ipp-blossom-prod'
                            yaml pod.getGPUYAML("${IMAGE_PREMERGE}", "${env.GPU_RESOURCE}", '8', '32Gi') // cpu: 8, memory: 32Gi
                            workspaceVolume persistentVolumeClaimWorkspaceVolume(claimName: "${PVC}", readOnly: false)
                            customWorkspace "${CUSTOM_WORKSPACE}-ci-2" // Use different workspace to avoid conflict with IT
                        }
                    }

                    steps {
                        script {
                            unstash "source_tree"

                            container('gpu') {
                                timeout(time: 4, unit: 'HOURS') {
                                    sh "$PREMERGE_SCRIPT $PREMERGE_CI_2_ARGUMENT"
                                }
                            }
                        }
                    }
                } // end of Unit Test stage
            } // end of parallel
        } // end of Premerge Test
    } // end of stages

    post {
        always {
            script {
                if (skipped) {
                    return
                }

                if (currentBuild.currentResult == "SUCCESS") {
                    githubHelper.updateCommitStatus("$BUILD_URL", "Success", GitHubCommitState.SUCCESS)
                } else {
                    // upload log only in case of build failure
                    def guardWords = ["gitlab.*?\\.com", "urm.*?\\.com"]
                    guardWords.add("nvidia-smi(?s)(.*?)(?=jenkins/version-def.sh)") // hide GPU info

                    githubHelper.uploadParallelLogs(this, env.JOB_NAME, env.BUILD_NUMBER, null, guardWords)

                    githubHelper.updateCommitStatus("$BUILD_URL", "Fail", GitHubCommitState.FAILURE)
                }

                if (TEMP_IMAGE_BUILD) {
                    deleteDockerTempTag("${PREMERGE_TAG}") // clean premerge temp image
                }
            }
        }
    }

} // end of pipeline

void uploadDocker(String IMAGE_NAME) {
    def DOCKER_CMD = "docker --config $WORKSPACE/.docker"
    retry(3) {
        sleep(time: 30, unit: "SECONDS")
        sh """
            echo $URM_CREDS_PSW | $DOCKER_CMD login $ARTIFACTORY_NAME -u $URM_CREDS_USR --password-stdin
            $DOCKER_CMD push $IMAGE_NAME
            $DOCKER_CMD logout $ARTIFACTORY_NAME
        """
    }
}

void deleteDockerTempTag(String tag) {
    if (!tag?.trim()) { // return if the tag is null or empty
        return
    }
    sh "curl -u $URM_CREDS_USR:$URM_CREDS_PSW -XDELETE https://${ARTIFACTORY_NAME}/artifactory/sw-spark-docker-local/plugin/${tag} || true"
}
