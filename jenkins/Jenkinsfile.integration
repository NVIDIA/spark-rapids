#!/usr/local/env groovy
/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
*
* Jenkins file for running spark3.0 integration tests
*
*/

@Library(['shared-libs', 'spark-jenkins-shared-lib']) _

def urmUrl="https://${ArtifactoryConstants.ARTIFACTORY_NAME}/artifactory/sw-spark-maven"
def CUDA_DOCKER="cuda10-1"
def CUDA_NAME=CUDA_DOCKER.replace("-", ".")
def IMAGE_NAME="${ArtifactoryConstants.ARTIFACTORY_NAME}/sw-spark-docker/plugin:it-centos7-$CUDA_NAME"

def podConf="""
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: "$CUDA_DOCKER"
    image: urm.nvidia.com/sw-spark-docker/plugin:it-ubuntu16-cuda10.1
    resources:
      limits:
        nvidia.com/gpu: 1
    restartPolicy: Never
    backoffLimit: 4
    tty: true

  - name: docker
    image: docker:19.03.1
    command:
    - sleep
    args:
    - 99d
    env:
      - name: DOCKER_HOST
        value: tcp://localhost:2375
  - name: docker-daemon
    image: docker:19.03.1-dind
    securityContext:
      privileged: true
    env:
      - name: DOCKER_TLS_CERTDIR
        value: ""

  nodeSelector:
    kubernetes.io/os: linux
"""
println podConf

pipeline {
    agent {
        kubernetes {
            label 'plugin-it'
            cloud 'sc-ipp-blossom-prod'
            yaml "${podConf}"
        }
    }

    options {
        ansiColor('xterm')
        timestamps()
        timeout(time: 240, unit: 'MINUTES')
        buildDiscarder(logRotator(numToKeepStr: '10'))
    }

    parameters {
        string(name: 'OVERWRITE_PARAMS', defaultValue: '',
            description: 'parameters format XXX_VER=xxx;YYY_VER=yyy;')
        string(name: 'REF', defaultValue: 'branch-0.2', description: 'Commit to build')
    }

    environment {
        JENKINS_ROOT  = 'jenkins'
        TEST_SCRIPT = '$JENKINS_ROOT/spark-tests.sh'
        LIBCUDF_KERNEL_CACHE_PATH='/tmp/.cudf'
        URM_CREDS = credentials("svcngcc_artifactory")
        ARTIFACTORY_NAME = "${ArtifactoryConstants.ARTIFACTORY_NAME}"
        URM_URL = "${urmUrl}"
        MVN_URM_MIRROR='-s jenkins/settings.xml -P mirror-apache-to-urm'
    }

    stages {
        stage('Update docker image') {
            steps {
                script {
                    container('docker') {
                        def CUDA_VER="$CUDA_NAME" - "cuda"
                        sh "docker pull $IMAGE_NAME || true"
                        def urmImageID=sh(returnStdout: true, script: "docker inspect -f {{'.Id'}} $IMAGE_NAME")
                        // Speed up Docker building via '--cache-from $IMAGE_NAME'
                        def buildImage=docker.build(IMAGE_NAME,
                            "-f jenkins/Dockerfile.integration.centos7 --build-arg CUDA_VER=$CUDA_VER \
                                --build-arg URM_URL=$URM_URL --cache-from $IMAGE_NAME -t $IMAGE_NAME .")
                        def buildImageID=sh(returnStdout: true, script: "docker inspect -f {{'.Id'}} $IMAGE_NAME")
                        if (! buildImageID.equals(urmImageID)) {
                            echo "Dockerfile updated, upload docker image to URM"
                            uploadDocker(IMAGE_NAME)
                        }
                    }
                }
            }
        }
        stage('IT on centos7 CUDA10.1') {
            steps {
                script {
                    container('cuda10-1') {
                        echo "Running integration tests on centos7 $CUDA_NAME"
                        sh "bash $TEST_SCRIPT"
                    }
                }
            }
        }
    } // end of stages
    post {
        always {
            script {
                def status = "failed"
                if (currentBuild.currentResult == "SUCCESS") {
                    status = "success"
                    slack("#rapidsai-spark-cicd", "Success", color: "#33CC33")
                }
                else {
                    slack("#rapidsai-spark-cicd", "Failed", color: "#FF0000")
                }
            }
            echo 'Pipeline finished!'
        }
    }
} // end of pipeline

void uploadDocker(String IMAGE_NAME) {
/*
    def DOCKER_CMD="docker --config $WORKSPACE/.docker"
    sh """
        echo $URM_CREDS_PSW | $DOCKER_CMD login $ARTIFACTORY_NAME -u $URM_CREDS_USR --password-stdin
        $DOCKER_CMD push $IMAGE_NAME
        $DOCKER_CMD logout $ARTIFACTORY_NAME
    """
*/
}

void slack(Map params = [:], String channel, String message) {
/*
    Map defaultParams = [
            color: "#000000",
            baseUrl: "${SparkConstants.SLACK_API_ENDPOINT}",
            tokenCredentialId: "slack_token"
    ]

    params["channel"] = channel
    params["message"] = "${BUILD_URL}\n" + message

    slackSend(defaultParams << params)
*/
}
