#!/usr/local/env groovy
/*
 * Copyright (c) 2019-2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
*
* Jenkins file for running spark3.0 integration tests
*
*/

pipeline {
    agent none

    options {
        ansiColor('xterm')
        timestamps()
        timeout(time: 240, unit: 'MINUTES')
        buildDiscarder(logRotator(numToKeepStr: '10'))
    }

    parameters {
        string(name: 'CUDF_VER', defaultValue: '0.14',
            description: '-Dcudf.version= \n\n Default for cudf version')
        string(name: 'CUDA_CLASSIFIER', defaultValue: '',
            description: '-Dclassifier=\n\n cuda10-1, cuda10-2, EMPTY as cuda10-1')
        string(name: 'PROJECT_VER', defaultValue: '0.1-SNAPSHOT',
            description: 'Default project version 0.1-SNAPSHOT')
        string(name: 'SPARK_VER', defaultValue: '3.0.1-SNAPSHOT',
            description: 'Default spark version 3.0.1-SNAPSHOT')
        string(name: 'SERVER_URL', defaultValue: 'https://urm.nvidia.com:443/artifactory/sw-spark-maven',
            description: 'Default maven repo URL where to download Spark3.0 tar file.')
        string(name: 'REF', defaultValue: 'branch-0.1', description: 'Commit to build')
    }

    environment {
        JENKINS_ROOT  = 'jenkins'
        TEST_SCRIPT = '$JENKINS_ROOT/spark-tests.sh'
        LIBCUDF_KERNEL_CACHE_PATH='/tmp'
        URM_CREDS = credentials("svcngcc_artifactory")
    }

    stages {
        stage('centos7 CUDA10.1') {
            agent { label 'docker-gpu' }
            steps {
                script {
                    def DOCKER_TAG=CUDA_CLASSIFIER.replaceAll("-", ".")
                    if ( DOCKER_TAG == "") {
                         DOCKER_TAG="cuda10.1"
                    }
                    echo "CUDA_CLASSIFIER: $CUDA_CLASSIFIER, DOCKER_TAG: $DOCKER_TAG"

                    def IMAGE_NAME="urm.nvidia.com/sw-spark-docker/plugin:it-centos7-$DOCKER_TAG"
                    def DOCKER_CMD="docker --config $WORKSPACE/.docker"
                    sh """
                        echo $URM_CREDS_PSW | $DOCKER_CMD login https://urm.nvidia.com -u $URM_CREDS_USR --password-stdin
                        $DOCKER_CMD pull $IMAGE_NAME
                        $DOCKER_CMD logout https://urm.nvidia.com
                    """

                    docker.image(IMAGE_NAME).inside("--runtime=nvidia -v ${HOME}/.zinc:${HOME}/.zinc:rw \
                        -v /etc/passwd:/etc/passwd -v /etc/group:/etc/group") {
                        echo "Running integration tests on centos7 $DOCKER_TAG"
                        sh "bash $TEST_SCRIPT"
                    }
                }
            }
        }
    } // end of stages
    post {
        always {
            script {
                def status = "failed"
                if (currentBuild.currentResult == "SUCCESS") {
                    status = "success"
                    slack("#rapidsai-spark-cicd", "Success", color: "#33CC33")
                }
                else {
                    slack("#rapidsai-spark-cicd", "Failed", color: "#FF0000")
                }
            }
            echo 'Pipeline finished!'
        }
    }
} // end of pipeline

void slack(Map params = [:], String channel, String message) {
    Map defaultParams = [
            color: "#000000",
            baseUrl: "https://nvidia.slack.com/services/hooks/jenkins-ci/",
            tokenCredentialId: "slack_token"
    ]

    params["channel"] = channel
    params["message"] = "${BUILD_URL}\n" + message

    slackSend(defaultParams << params)
}
