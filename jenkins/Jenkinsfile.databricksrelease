#!/usr/local/env groovy
/*
 * Copyright (c) 2020, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
*
* Jenkinsfile for building and deploy rapids-plugin for Databricks to public repo
*
*/

def SERVERS_MAP = [
    Local:    ' ',
    Sonatype: 'https://oss.sonatype.org/service/local/staging/deploy/maven2'
]

def SEC_IDS = [
    Local:    ['local-gpg-passphrase',  'local-gpg-private-key',  'local-username-password'],
    Sonatype: ['SPARK_RAPIDS_GPG_PASSPHRASE', 'SPARK_RAPIDS_GPG_PRIVATE_KEY', 'SPARK_SONATYPE_USERPASS']
]

pipeline {
    agent {
        dockerfile {
            label 'vanilla||docker-deploy||docker-gpu'
            filename 'Dockerfile.ubuntu16'
            dir "jenkins"
            args '--runtime=nvidia -v ${HOME}/.m2:${HOME}/.m2:rw \
                -v ${HOME}/.zinc:${HOME}/.zinc:rw'
        }
    }

    options {
        ansiColor('xterm')
        timeout(time: 120, unit: 'MINUTES')
        buildDiscarder(logRotator(numToKeepStr: '10'))
    }

    parameters {
        choice(name: 'DEPLOY_TO', choices: ['Sonatype'],
            description: 'Where to deploy artifacts to')
        string(name: 'DATABRICKS_VERSION',
                defaultValue: '0.2-databricks-SNAPSHOT', description: 'Version to set')
        string(name: 'CUDF_VERSION',
                defaultValue: '0.15-SNAPSHOT', description: 'Cudf version to use')
        string(name: 'CUDA_VERSION',
                defaultValue: 'cuda10-1', description: 'cuda version to use')
        string(name: 'REF', defaultValue: 'branch-0.2', description: 'Commit to build')
    }

    environment {
        JENKINS_ROOT='jenkins'
        IMAGE_NAME="urm.nvidia.com/sw-spark-docker/plugin:dev-ubuntu16-cuda10.1"
        LIBCUDF_KERNEL_CACHE_PATH='/tmp/.cudf'
        MVN_MIRROR='-s jenkins/settings.xml -P mirror-apache-to-urm'
        URM_CREDS = credentials("svcngcc_artifactory")
        DATABRICKS_TOKEN = credentials("SPARK_DATABRICKS_TOKEN")
        DIST_PL='dist'
        SQL_PL='sql-plugin'
        SCALA_VERSION = '2.12'
        SPARK_VERSION = '3.0.0'
        CI_RAPIDS_JAR = 'rapids-4-spark_2.12-0.1-SNAPSHOT-ci.jar'
        CI_CUDF_JAR = 'cudf-0.14-cuda10-1.jar'
    }

    stages {
        stage('Build') {
            steps {
                script {
                    sshagent(credentials : ['svcngcc_pubpriv']) {
                        sh "mvn versions:set -DnewVersion=0.2.0-databricks && git clean -d -f"
                        sh "patch -p1 < ./jenkins/databricks/dbimports.patch"
                        sh "tar -zcvf spark-rapids-ci.tgz * || true"
                        sh "python3.6 ./jenkins/databricks/run-tests.py -z ./spark-rapids-ci.tgz -t $DATABRICKS_TOKEN -p /home/svcngcc/.ssh/id_rsa -l ./jenkins/databricks/build.sh -j $CI_RAPIDS_JAR -b $DATABRICKS_VERSION -k $SPARK_VERSION -a $SCALA_VERSION -f $CUDF_VERSION -u $CUDA_VERSION -m $CI_CUDF_JAR"
                    }
                }
            }
        }
        stage("Deploy") {
            environment {
                SERVER_ID='ossrh'
                SERVER_URL="${SERVERS_MAP["$DEPLOY_TO"]}"
                GPG_PASSPHRASE=credentials("${SEC_IDS["$DEPLOY_TO"][0]}")
                GPG_FILE=credentials("${SEC_IDS["$DEPLOY_TO"][1]}")
                SONATYPE=credentials("${SEC_IDS["$DEPLOY_TO"][2]}")
                GNUPGHOME="${WORKSPACE}/.gnupg"
            }
            steps {
                script {
                    sh 'rm -rf $GNUPGHOME'
                    sh 'gpg --import $GPG_FILE'
                    retry (3) {
                        sh "bash $JENKINS_ROOT/deploy.sh true true"
                    }
                }
            }
        }
        stage('Cleanup') {
            steps {
                script {
                    sh "python3.6 ./jenkins/databricks/shutdown.py -t $DATABRICKS_TOKEN"
                }
            }
        }
    } // End of stages
} // end of pipeline
