27,34c27,34
<   def dateFormatInRead(csvOpts: CSVOptions): Option[String] = {
<     // spark 2.x uses FastDateFormat, use getPattern
<     Option(csvOpts.dateFormat.getPattern)
<   }
< 
<   def timestampFormatInRead(csvOpts: CSVOptions): Option[String] = {
<     // spark 2.x uses FastDateFormat, use getPattern
<     Option(csvOpts.timestampFormat.getPattern)
---
>   def tagSupport(scanMeta: ScanMeta[CSVScan]) : Unit = {
>     val scan = scanMeta.wrapped
>     tagSupport(
>       scan.sparkSession,
>       scan.dataSchema,
>       scan.readDataSchema,
>       scan.options.asScala.toMap,
>       scanMeta)
42c42
<       meta: RapidsMeta[_, _]): Unit = {
---
>       meta: RapidsMeta[_, _, _]): Unit = {
67,68d66
<     // 2.x only supports delimiter as char
<     /*
72d69
<     */
74,75c71
<     // delimiter is char in 2.x
<     if (parsedOptions.delimiter > 127) {
---
>     if (parsedOptions.delimiter.codePointAt(0) > 127) {
105,109d100
<     // 2.x doesn't have linSeparator config
<     // CSV text with '\n', '\r' and '\r\n' as line separators.
<     // Since I have no way to check in 2.x we will just assume it works for explain until
<     // they move to 3.x
<     /*
113d103
<     */
154,156c144
< 
<       // Spark 2.x doesn't have zoneId, so use timeZone and then to id
<       if (!TypeChecks.areTimestampsSupported(parsedOptions.timeZone.toZoneId)) {
---
>       if (!TypeChecks.areTimestampsSupported(parsedOptions.zoneId)) {
159c147
<       timestampFormatInRead(parsedOptions).foreach { tsFormat =>
---
>       FileOptionsShims.timestampFormatInRead(parsedOptions).foreach { tsFormat =>
