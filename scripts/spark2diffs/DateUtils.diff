2c2
<  * Copyright (c) 2022, NVIDIA CORPORATION.
---
>  * Copyright (c) 2020-2022, NVIDIA CORPORATION.
22a23,25
> import ai.rapids.cudf.{DType, Scalar}
> import com.nvidia.spark.rapids.VersionUtils.isSpark320OrLater
> 
62,63c65,67
<   // Spark 2.x - removed isSpark320orlater checks
<   def specialDatesDays: Map[String, Int] = {
---
>   def specialDatesDays: Map[String, Int] = if (isSpark320OrLater) {
>     Map.empty
>   } else {
74c78,80
<   def specialDatesSeconds: Map[String, Long] = {
---
>   def specialDatesSeconds: Map[String, Long] = if (isSpark320OrLater) {
>     Map.empty
>   } else {
76,77c82
<     // spark 2.4 Date utils are different
<     val now = DateTimeUtils.instantToMicros(Instant.now())
---
>     val now = DateTimeUtils.currentTimestamp()
87c92,94
<   def specialDatesMicros: Map[String, Long] = {
---
>   def specialDatesMicros: Map[String, Long] = if (isSpark320OrLater) {
>     Map.empty
>   } else {
89c96
<     val now = DateTimeUtils.instantToMicros(Instant.now())
---
>     val now = DateTimeUtils.currentTimestamp()
99c106,123
<   def currentDate(): Int = Math.toIntExact(LocalDate.now().toEpochDay)
---
>   def fetchSpecialDates(unit: DType): Map[String, () => Scalar] = unit match {
>     case DType.TIMESTAMP_DAYS =>
>       DateUtils.specialDatesDays.map { case (k, v) =>
>         k -> (() => Scalar.timestampDaysFromInt(v))
>       }
>     case DType.TIMESTAMP_SECONDS =>
>       DateUtils.specialDatesSeconds.map { case (k, v) =>
>         k -> (() => Scalar.timestampFromLong(unit, v))
>       }
>     case DType.TIMESTAMP_MICROSECONDS =>
>       DateUtils.specialDatesMicros.map { case (k, v) =>
>         k -> (() => Scalar.timestampFromLong(unit, v))
>       }
>     case _ =>
>       throw new IllegalArgumentException(s"unsupported DType: $unit")
>   }
> 
>   def currentDate(): Int = localDateToDays(LocalDate.now())
