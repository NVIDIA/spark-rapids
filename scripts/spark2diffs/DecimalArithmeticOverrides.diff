19c19,20
< import com.nvidia.spark.rapids.{BaseExprMeta, CastExprMeta, DecimalUtil, ExprChecks, ExprMeta, ExprRule, GpuOverrides, LiteralExprMeta, TypeSig, UnaryExprMeta}
---
> import ai.rapids.cudf.DType
> import com.nvidia.spark.rapids.{BaseExprMeta, CastExprMeta, DecimalUtil, ExprChecks, ExprMeta, ExprRule, GpuCheckOverflow, GpuExpression, GpuOverrides, GpuPromotePrecision, LiteralExprMeta, TypeSig, UnaryExprMeta}
22c23
< import org.apache.spark.sql.catalyst.expressions.{Cast, CheckOverflow, Divide, Expression, Literal, Multiply, PromotePrecision}
---
> import org.apache.spark.sql.catalyst.expressions.{CastBase, CheckOverflow, Divide, Expression, Literal, Multiply, PromotePrecision}
34c35
< 
---
>         override def convertToGpu(child: Expression): GpuExpression = GpuPromotePrecision(child)
52,53c53
<                   // allowNegativeScaleOfDecimalEnabled is not in 2.x assume its default false
<                   val t = if (s < 0 && !false) {
---
>                   val t = if (s < 0 && !SQLConf.get.allowNegativeScaleOfDecimalEnabled) {
66,67c66
<             // Spark 2.X only has Cast, no AnsiCast so no CastBase, hardcode here to Cast
<             case p: PromotePrecision if p.child.isInstanceOf[Cast] &&
---
>             case p: PromotePrecision if p.child.isInstanceOf[CastBase] &&
69c68
<               val c = p.child.asInstanceOf[Cast]
---
>               val c = p.child.asInstanceOf[CastBase]
108a108,135
>         override def convertToGpu(): GpuExpression = {
>           // Prior to Spark 3.4.0
>           // Division and Multiplication of Decimal types is a little odd. Spark will cast the
>           // inputs to a common wider value where the scale is the max of the two input scales,
>           // and the precision is max of the two input non-scale portions + the new scale. Then it
>           // will do the divide or multiply as a BigDecimal value but lie about the return type.
>           // Finally here in CheckOverflow it will reset the scale and check the precision so that
>           // Spark knows it fits in the final desired result.
>           // Here we try to strip out the extra casts, etc to get to as close to the original
>           // query as possible. This lets us then calculate what CUDF needs to get the correct
>           // answer, which in some cases is a lot smaller.
> 
>           a.child match {
>             case _: Divide =>
>               // GpuDecimalDivide includes the overflow check in it.
>               GpuDecimalDivide(lhs.convertToGpu(), rhs.convertToGpu(), wrapped.dataType)
>             case _: Multiply =>
>               // GpuDecimal*Multiply includes the overflow check in it
>               val intermediatePrecision =
>                 GpuDecimalMultiply.nonRoundedIntermediatePrecision(lhsDecimalType,
>                   rhsDecimalType, a.dataType)
>               GpuDecimalMultiply(lhs.convertToGpu(), rhs.convertToGpu(), wrapped.dataType,
>                 useLongMultiply = intermediatePrecision > DType.DECIMAL128_MAX_PRECISION)
>             case _ =>
>               GpuCheckOverflow(childExprs.head.convertToGpu(),
>                 wrapped.dataType, wrapped.nullOnOverflow)
>           }
>         }
