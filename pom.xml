<?xml version="1.0" encoding="UTF-8"?>
<!--
  Copyright (c) 2020-2021, NVIDIA CORPORATION.

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.nvidia</groupId>
    <artifactId>rapids-4-spark-parent</artifactId>
    <name>RAPIDS Accelerator for Apache Spark Root Project</name>
    <description>The root project of the RAPIDS Accelerator for Apache Spark</description>
    <version>21.10.0-SNAPSHOT</version>
    <packaging>pom</packaging>

    <url>https://nvidia.github.io/spark-rapids/</url>
    <licenses>
        <license>
            <name>Apache License, Version 2.0</name>
            <url>https://www.apache.org/licenses/LICENSE-2.0.txt</url>
            <distribution>repo</distribution>
        </license>
    </licenses>
    <scm>
        <connection>scm:git:https://github.com/NVIDIA/spark-rapids.git</connection>
        <developerConnection>scm:git:git@github.com:NVIDIA/spark-rapids.git</developerConnection>
        <tag>HEAD</tag>
        <url>https://github.com/NVIDIA/spark-rapids</url>
    </scm>
    <developers>
        <developer>
            <id>revans2</id>
            <name>Robert Evans</name>
            <email>roberte@nvidia.com</email>
            <roles>
                <role>Committer</role>
            </roles>
            <timezone>-6</timezone>
        </developer>
        <developer>
            <id>tgravescs</id>
            <name>Thomas Graves</name>
            <email>tgraves@nvidia.com</email>
            <roles>
                <role>Committer</role>
            </roles>
            <timezone>-6</timezone>
        </developer>
        <developer>
            <id>jlowe</id>
            <name>Jason Lowe</name>
            <email>jlowe@nvidia.com</email>
            <roles>
                <role>Committer</role>
            </roles>
            <timezone>-6</timezone>
        </developer>
    </developers>

    <modules>
        <module>dist</module>
        <module>integration_tests</module>
        <module>shims</module>
        <module>shuffle-plugin</module>
        <module>sql-plugin</module>
        <module>tests</module>
        <module>udf-compiler</module>
        <module>udf-examples</module>
    </modules>

    <profiles>
        <profile>
            <id>default</id>
            <activation>
                <activeByDefault>true</activeByDefault>
            </activation>
            <modules>
                <module>api_validation</module>
                <module>tools</module>
            </modules>
       </profile>
       <profile>
            <id>release301</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>301</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark301</spark.version.classifier>
                <spark.version>${spark301.version}</spark.version>
                <spark.test.version>${spark301.version}</spark.test.version>
            </properties>
            <modules>
                <module>api_validation</module>
            </modules>
        </profile>
        <profile>
            <id>release301emr</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>301emr</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark301emr</spark.version.classifier>
                <spark.version>${spark301emr.version}</spark.version>
                <spark.test.version>${spark301emr.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>release302</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>302</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark302</spark.version.classifier>
                <spark.version>${spark302.version}</spark.version>
                <spark.test.version>${spark302.version}</spark.test.version>
            </properties>
            <modules>
                <module>api_validation</module>
            </modules>
        </profile>
        <profile>
            <id>release303</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>303</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark303</spark.version.classifier>
                <spark.version>${spark303.version}</spark.version>
                <spark.test.version>${spark303.version}</spark.test.version>
            </properties>
            <modules>
                <module>api_validation</module>
            </modules>
        </profile>
        <profile>
            <id>release304</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>304</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark304</spark.version.classifier>
                <spark.version>${spark304.version}</spark.version>
                <spark.test.version>${spark304.version}</spark.test.version>
            </properties>
            <modules>
                <module>api_validation</module>
            </modules>
        </profile>
        <profile>
            <id>release311</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>311</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark311</spark.version.classifier>
                <spark.version>${spark311.version}</spark.version>
                <spark.test.version>${spark311.version}</spark.test.version>
            </properties>
            <modules>
                <module>api_validation</module>
                <module>tools</module>
            </modules>
        </profile>
        <profile>
            <!-- Note databricks requires 2 properties -Ddatabricks and -Dbuildver=[301db,311db] -->
            <id>release301db</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>301db</value>
                </property>
            </activation>
            <properties>
                <!-- Downgrade scala plugin version due to: https://github.com/sbt/sbt/issues/4305 -->
                <scala.plugin.version>3.4.4</scala.plugin.version>
                <shim.module.name>spark301db</shim.module.name>
                <spark.version.classifier>spark301-databricks</spark.version.classifier>
                <!--
                     Note that we are using the Spark version for all of the Databricks dependencies as well.
                     The jenkins/databricks/build.sh script handles installing the jars as maven artifacts.
                     This is to make it easier and not have to change version numbers for each individual dependency
                     and deal with differences between Databricks versions
                -->
                <spark.version>${spark301db.version}</spark.version>
                <spark.test.version>${spark301db.version}</spark.test.version>
                <rat.consoleOutput>true</rat.consoleOutput>
                <hive.storage.api.version>${spark301db.version}</hive.storage.api.version>
                <protobuf.java.version>${spark301db.version}</protobuf.java.version>
            </properties>
        </profile>
        <profile>
            <!-- Note databricks requires 2 properties -Ddatabricks and -Dbuildver=[301db,311db] -->
            <id>release311db</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>311db</value>
                </property>
            </activation>
            <properties>
                <!-- Downgrade scala plugin version due to: https://github.com/sbt/sbt/issues/4305 -->
                <scala.plugin.version>3.4.4</scala.plugin.version>
                <shim.module.name>spark311db</shim.module.name>
                <spark.version.classifier>spark311-databricks</spark.version.classifier>
                <!--
                     Note that we are using the Spark version for all of the Databricks dependencies as well.
                     The jenkins/databricks/build.sh script handles installing the jars as maven artifacts.
                     This is to make it easier and not have to change version numbers for each individual dependency
                     and deal with differences between Databricks versions
                -->
                <spark.version>${spark311db.version}</spark.version>
                <spark.test.version>${spark311db.version}</spark.test.version>
                <rat.consoleOutput>true</rat.consoleOutput>
                <hive.storage.api.version>${spark311db.version}</hive.storage.api.version>
                <protobuf.java.version>${spark311db.version}</protobuf.java.version>
            </properties>
        </profile>
        <profile>
            <id>release312</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>312</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark312</spark.version.classifier>
                <spark.version>${spark312.version}</spark.version>
                <spark.test.version>${spark312.version}</spark.test.version>
            </properties>
            <modules>
                <module>api_validation</module>
            </modules>
        </profile>
        <profile>
            <id>release313</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>313</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark313</spark.version.classifier>
                <spark.version>${spark313.version}</spark.version>
                <spark.test.version>${spark313.version}</spark.test.version>
            </properties>
            <modules>
                <module>api_validation</module>
            </modules>
        </profile>
        <profile>
            <id>release320</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>320</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark320</spark.version.classifier>
                <spark.version>${spark320.version}</spark.version>
                <spark.test.version>${spark320.version}</spark.test.version>
            </properties>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.codehaus.mojo</groupId>
                        <artifactId>build-helper-maven-plugin</artifactId>
                        <executions>
                            <execution>
                                <id>add-profile-src</id>
                                <goals><goal>add-source</goal></goals>
                                <phase>generate-sources</phase>
                                <configuration>
                                    <sources>
                                        <source>${project.basedir}/src/main/spark${buildver}/scala</source>
                                    </sources>
                                </configuration>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>
        <profile>
            <id>release311cdh</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>311cdh</value>
                </property>
            </activation>
            <properties>
                <spark.version.classifier>spark311cdh</spark.version.classifier>
                <spark.version>${spark311cdh.version}</spark.version>
                <spark.test.version>${spark311cdh.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>udf-compiler</id>
            <modules>
                <module>udf-compiler</module>
            </modules>
        </profile>
        <profile>
            <id>source-javadoc</id>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-source-plugin</artifactId>
                        <version>3.0.0</version>
                        <executions>
                            <execution>
                                <id>attach-source</id>
                                <goals>
                                    <goal>jar-no-fork</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-javadoc-plugin</artifactId>
                        <version>3.0.0</version>
                        <executions>
                            <execution>
                                <id>attach-javadoc</id>
                                <goals>
                                    <goal>jar</goal>
                                </goals>
                            </execution>
                        </executions>
                        <configuration>
                            <doclint>none</doclint>
                        </configuration>
                    </plugin>
                </plugins>
            </build>
        </profile>
        <profile>
            <id>databricks301</id>
            <properties>
                <rat.consoleOutput>true</rat.consoleOutput>
            </properties>
        </profile>
        <profile>
            <id>databricks311</id>
            <properties>
                <rat.consoleOutput>true</rat.consoleOutput>
            </properties>
        </profile>
        <profile>
            <id>spark301dbtests</id>
            <properties>
                <spark.test.version>${spark301db.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark311dbtests</id>
            <properties>
                <spark.test.version>${spark311db.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark301tests</id>
            <properties>
                <spark.test.version>${spark301.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark302tests</id>
            <properties>
                <spark.test.version>${spark302.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark303tests</id>
            <properties>
                <spark.test.version>${spark303.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark304tests</id>
            <properties>
                <spark.test.version>${spark304.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark311tests</id>
            <properties>
                <spark.test.version>${spark311.version}</spark.test.version>
            </properties>
            <modules>
                <module>tests-spark310+</module>
            </modules>
        </profile>
        <profile>
            <id>spark311cdhtests</id>
            <properties>
                <spark.test.version>${spark311cdh.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark312tests</id>
            <properties>
                <spark.test.version>${spark312.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark313tests</id>
            <properties>
                <spark.test.version>${spark313.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>spark320tests</id>
            <properties>
                <spark.test.version>${spark320.version}</spark.test.version>
            </properties>
        </profile>
        <profile>
            <id>cuda11</id>
            <properties>
                <cuda.version>cuda11</cuda.version>
            </properties>
        </profile>
    </profiles>

    <properties>
        <maven.compiler.source>1.8</maven.compiler.source>
        <maven.compiler.target>1.8</maven.compiler.target>
        <spark.version>${spark301.version}</spark.version>
        <spark.test.version>${spark301.version}</spark.test.version>
        <spark.version.classifier></spark.version.classifier>
        <cuda.version>cuda11</cuda.version>
        <cudf.version>21.10.0-SNAPSHOT</cudf.version>
        <scala.binary.version>2.12</scala.binary.version>
        <scala.version>2.12.8</scala.version>
        <orc.version>1.5.8</orc.version>
        <orc.classifier></orc.classifier>
        <!--
             If the shade package changes we need to also update jenkins/spark-premerge-build.sh
             so code coverage does not include the shaded classes.
        -->
        <rapids.shade.package>com.nvidia.shaded.spark</rapids.shade.package>
        <test.exclude.tags></test.exclude.tags>
        <test.include.tags></test.include.tags>
        <rapids.shuffle.manager.override>true</rapids.shuffle.manager.override>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.sourceEncoding>UTF-8</project.reporting.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <pytest.TEST_TAGS>not qarun</pytest.TEST_TAGS>
        <pytest.TEST_PARALLEL></pytest.TEST_PARALLEL>
        <pytest.TEST_TYPE>developer</pytest.TEST_TYPE>
        <rat.consoleOutput>false</rat.consoleOutput>
        <!--
         If you update a dependency version so it is no longer a SNAPSHOT
         please update the snapshot-shims profile as well so it is accurate -->
        <spark301.version>3.0.1</spark301.version>
        <spark301db.version>3.0.1-databricks</spark301db.version>
        <spark301emr.version>3.0.1-amzn</spark301emr.version>
        <spark302.version>3.0.2</spark302.version>
        <spark303.version>3.0.3</spark303.version>
        <spark304.version>3.0.4-SNAPSHOT</spark304.version>
        <spark311db.version>3.1.1-databricks</spark311db.version>
        <spark311.version>3.1.1</spark311.version>
        <spark311cdh.version>3.1.1.3.1.7270.0-253</spark311cdh.version>
        <spark312.version>3.1.2</spark312.version>
        <spark313.version>3.1.3-SNAPSHOT</spark313.version>
        <spark320.version>3.2.0-SNAPSHOT</spark320.version>
        <mockito.version>3.6.0</mockito.version>
        <scala.plugin.version>4.3.0</scala.plugin.version>
        <maven.jar.plugin.version>3.2.0</maven.jar.plugin.version>
        <scalatest-maven-plugin.version>2.0.2</scalatest-maven-plugin.version>
        <guava.cdh.version>30.0-jre</guava.cdh.version>
        <shim.module.name>${spark.version.classifier}</shim.module.name>
        <slf4j.version>1.7.30</slf4j.version>
        <hive.storage.api.version>2.6.0</hive.storage.api.version>
        <protobuf.java.version>2.5.0</protobuf.java.version>
        <flatbuffers.java.version>1.11.0</flatbuffers.java.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
              <groupId>ai.rapids</groupId>
              <artifactId>cudf</artifactId>
              <version>${cudf.version}</version>
              <classifier>${cuda.version}</classifier>
              <scope>provided</scope>
            </dependency>
            <dependency>
              <groupId>org.slf4j</groupId>
              <artifactId>jul-to-slf4j</artifactId>
              <version>${slf4j.version}</version>
              <!-- runtime scope is appropriate, but causes SBT build problems -->
            </dependency>
            <dependency>
              <groupId>org.slf4j</groupId>
              <artifactId>jcl-over-slf4j</artifactId>
              <version>${slf4j.version}</version>
              <!-- runtime scope is appropriate, but causes SBT build problems -->
            </dependency>
            <dependency>
              <groupId>org.scala-lang</groupId>
              <artifactId>scala-library</artifactId>
              <version>${scala.version}</version>
              <scope>provided</scope>
            </dependency>
            <dependency>
              <groupId>org.apache.spark</groupId>
              <artifactId>spark-annotation_${scala.binary.version}</artifactId>
              <version>${spark.version}</version>
              <scope>provided</scope>
            </dependency>
            <dependency>
              <groupId>org.apache.spark</groupId>
              <artifactId>spark-hive_${scala.binary.version}</artifactId>
              <version>${spark.version}</version>
              <scope>provided</scope>
            </dependency>
            <dependency>
              <groupId>org.apache.spark</groupId>
              <artifactId>spark-sql_${scala.binary.version}</artifactId>
              <version>${spark.version}</version>
              <scope>provided</scope>
            </dependency>
            <dependency>
              <groupId>org.apache.orc</groupId>
              <artifactId>orc-core</artifactId>
              <version>${orc.version}</version>
              <classifier>${orc.classifier}</classifier>
              <exclusions>
                <exclusion>
                  <groupId>javax.xml.bind</groupId>
                  <artifactId>jaxb-api</artifactId>
                </exclusion>
                <exclusion>
                  <groupId>org.apache.hadoop</groupId>
                  <artifactId>hadoop-common</artifactId>
                </exclusion>
                <exclusion>
                  <groupId>org.apache.hadoop</groupId>
                  <artifactId>hadoop-hdfs</artifactId>
                </exclusion>
                <exclusion>
                  <groupId>org.apache.hive</groupId>
                  <artifactId>hive-storage-api</artifactId>
                </exclusion>
              </exclusions>
            </dependency>
            <dependency>
              <groupId>org.apache.orc</groupId>
              <artifactId>orc-mapreduce</artifactId>
              <version>${orc.version}</version>
              <classifier>${orc.classifier}</classifier>
              <exclusions>
                <exclusion>
                  <groupId>org.apache.hadoop</groupId>
                  <artifactId>hadoop-common</artifactId>
                </exclusion>
                <exclusion>
                  <groupId>org.apache.hadoop</groupId>
                  <artifactId>hadoop-mapreduce-client-core</artifactId>
                </exclusion>
                <exclusion>
                  <groupId>org.apache.orc</groupId>
                  <artifactId>orc-core</artifactId>
                </exclusion>
                <exclusion>
                  <groupId>org.apache.hive</groupId>
                  <artifactId>hive-storage-api</artifactId>
                </exclusion>
                <exclusion>
                  <groupId>com.esotericsoftware</groupId>
                  <artifactId>kryo-shaded</artifactId>
                </exclusion>
              </exclusions>
            </dependency>
            <dependency>
              <groupId>org.apache.orc</groupId>
              <artifactId>orc-shims</artifactId>
              <version>${orc.version}</version>
              <exclusions>
                <exclusion>
                  <groupId>org.apache.hadoop</groupId>
                  <artifactId>hadoop-common</artifactId>
                </exclusion>
                <exclusion>
                  <groupId>org.apache.hadoop</groupId>
                  <artifactId>hadoop-hdfs</artifactId>
                </exclusion>
              </exclusions>
            </dependency>
            <dependency>
              <groupId>org.apache.hive</groupId>
              <artifactId>hive-storage-api</artifactId>
              <version>${hive.storage.api.version}</version>
            </dependency>
            <dependency>
              <groupId>com.google.protobuf</groupId>
              <artifactId>protobuf-java</artifactId>
              <version>${protobuf.java.version}</version>
            </dependency>
            <dependency>
              <groupId>com.google.flatbuffers</groupId>
              <artifactId>flatbuffers-java</artifactId>
              <version>${flatbuffers.java.version}</version>
            </dependency>
            <dependency>
              <groupId>org.rogach</groupId>
              <artifactId>scallop_${scala.binary.version}</artifactId>
              <version>3.5.1</version>
            </dependency>
            <dependency>
              <groupId>org.scalatest</groupId>
              <artifactId>scalatest_${scala.binary.version}</artifactId>
              <version>3.0.5</version>
              <scope>test</scope>
            </dependency>
            <dependency>
              <groupId>org.junit.jupiter</groupId>
              <artifactId>junit-jupiter-api</artifactId>
              <version>5.4.2</version>
              <scope>test</scope>
            </dependency>
            <dependency>
              <groupId>org.mockito</groupId>
              <artifactId>mockito-core</artifactId>
              <version>${mockito.version}</version>
              <scope>test</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <build>
        <pluginManagement>
            <plugins>
                <plugin>
                    <groupId>org.codehaus.mojo</groupId>
                    <artifactId>build-helper-maven-plugin</artifactId>
                    <version>3.2.0</version>
                    <executions>
                        <execution>
                            <id>add-profile-src</id>
                            <goals><goal>add-source</goal></goals>
                            <phase>generate-sources</phase>
                            <configuration>
                                <sources>
                                    <source>${project.basedir}/src/main/spark301/scala</source>
                                </sources>
                            </configuration>
                        </execution>
                    </executions>
                </plugin>
                <plugin>
                  <groupId>org.apache.maven.plugins</groupId>
                  <artifactId>maven-antrun-plugin</artifactId>
                  <version>1.8</version>
                </plugin>
                <plugin>
                  <groupId>org.apache.maven.plugins</groupId>
                  <artifactId>maven-shade-plugin</artifactId>
                  <version>3.2.1</version>
                </plugin>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-surefire-plugin</artifactId>
                    <version>2.12.4</version>
                </plugin>
                <plugin>
                    <groupId>net.alchim31.maven</groupId>
                    <artifactId>scala-maven-plugin</artifactId>
                    <version>${scala.plugin.version}</version>
                    <executions>
                        <execution>
                            <id>eclipse-add-source</id>
                            <goals>
                                <goal>add-source</goal>
                            </goals>
                        </execution>
                        <execution>
                            <id>scala-compile-first</id>
                            <phase>process-resources</phase>
                            <goals>
                                <goal>compile</goal>
                            </goals>
                        </execution>
                        <execution>
                            <id>scala-test-compile-first</id>
                            <phase>process-test-resources</phase>
                            <goals>
                                <goal>testCompile</goal>
                            </goals>
                        </execution>
                        <execution>
                            <id>attach-scaladocs</id>
                            <phase>verify</phase>
                            <goals>
                                <goal>doc-jar</goal>
                            </goals>
                        </execution>
                    </executions>
                    <configuration>
                        <scalaVersion>${scala.version}</scalaVersion>
                        <checkMultipleScalaVersions>true</checkMultipleScalaVersions>
                        <failOnMultipleScalaVersions>true</failOnMultipleScalaVersions>
                        <recompileMode>incremental</recompileMode>
                        <args>
                            <arg>-unchecked</arg>
                            <arg>-deprecation</arg>
                            <arg>-feature</arg>
                            <arg>-explaintypes</arg>
                            <arg>-Yno-adapted-args</arg>
                        </args>
                        <jvmArgs>
                            <jvmArg>-Xms1024m</jvmArg>
                            <jvmArg>-Xmx1024m</jvmArg>
                        </jvmArgs>
                        <javacArgs>
                            <javacArg>-source</javacArg>
                            <javacArg>${maven.compiler.source}</javacArg>
                            <javacArg>-target</javacArg>
                            <javacArg>${maven.compiler.target}</javacArg>
                            <javacArg>-Xlint:all,-serial,-path,-try</javacArg>
                        </javacArgs>
                    </configuration>
                </plugin>
                <plugin>
                    <groupId>org.scalatest</groupId>
                    <artifactId>scalatest-maven-plugin</artifactId>
                    <version>${scalatest-maven-plugin.version}</version>
                    <configuration>
                        <reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
                        <junitxml>.</junitxml>
                        <filereports>scala-test-output.txt</filereports>
                        <argLine>${argLine} -ea -Xmx4g -Xss4m</argLine>
                        <stderr/>
                        <systemProperties>
                            <rapids.shuffle.manager.override>${rapids.shuffle.manager.override}</rapids.shuffle.manager.override>
                            <ai.rapids.refcount.debug>true</ai.rapids.refcount.debug>
                            <java.awt.headless>true</java.awt.headless>
                            <java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>
                            <spark.ui.enabled>false</spark.ui.enabled>
                            <spark.ui.showConsoleProgress>false</spark.ui.showConsoleProgress>
                            <spark.unsafe.exceptionOnMemoryLeak>true</spark.unsafe.exceptionOnMemoryLeak>
                        </systemProperties>
                        <tagsToExclude>${test.exclude.tags}</tagsToExclude>
                        <tagsToInclude>${test.include.tags}</tagsToInclude>
                    </configuration>
                    <executions>
                        <execution>
                            <id>test</id>
                            <goals>
                                <goal>test</goal>
                            </goals>
                        </execution>
                    </executions>
                </plugin>
                <plugin>
                    <groupId>org.scalastyle</groupId>
                    <artifactId>scalastyle-maven-plugin</artifactId>
                    <version>1.0.0</version>
                    <configuration>
                        <verbose>false</verbose>
                        <failOnViolation>true</failOnViolation>
                        <includeTestSourceDirectory>false</includeTestSourceDirectory>
                        <failOnWarning>false</failOnWarning>
                        <sourceDirectory>${basedir}/src/main/scala</sourceDirectory>
                        <testSourceDirectory>${basedir}/src/test/scala</testSourceDirectory>
                        <configLocation>scalastyle-config.xml</configLocation>
                        <outputFile>${basedir}/target/scalastyle-output.xml</outputFile>
                        <inputEncoding>${project.build.sourceEncoding}</inputEncoding>
                        <outputEncoding>${project.reporting.outputEncoding}</outputEncoding>
                    </configuration>
                    <executions>
                        <execution>
                            <goals>
                                <goal>check</goal>
                            </goals>
                        </execution>
                    </executions>
                </plugin>
                <plugin>
                    <groupId>org.apache.rat</groupId>
                    <artifactId>apache-rat-plugin</artifactId>
                    <version>0.13</version>
                    <configuration>
                        <consoleOutput>${rat.consoleOutput}</consoleOutput>
                    </configuration>
                    <executions>
                        <execution>
                            <phase>verify</phase>
                            <goals>
                                <goal>check</goal>
                            </goals>
                        </execution>
                    </executions>
                </plugin>
                <plugin>
                    <groupId>org.jacoco</groupId>
                    <artifactId>jacoco-maven-plugin</artifactId>
                    <version>0.8.5</version>
                </plugin>
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-jar-plugin</artifactId>
                    <version>${maven.jar.plugin.version}</version>
                    <executions>
                        <execution>
                            <id>default-test-jar</id>
                            <goals>
                                <goal>test-jar</goal>
                            </goals>
                            <configuration>
                                <classifier>${spark.version.classifier}tests</classifier>
                            </configuration>
                        </execution>
                    </executions>
                </plugin>
                <plugin>
                    <groupId>org.codehaus.mojo</groupId>
                    <artifactId>exec-maven-plugin</artifactId>
                    <version>3.0.0</version>
                </plugin>
            </plugins>
        </pluginManagement>

        <plugins>
            <plugin>
                <groupId>org.apache.rat</groupId>
                <artifactId>apache-rat-plugin</artifactId>
                <configuration>
                    <excludes>
                        <exclude>**/*.md</exclude>
                        <exclude>**/*.iml</exclude>
                        <exclude>NOTICE-binary</exclude>
                        <exclude>docs/dev/idea-code-style-settings.xml</exclude>
                        <exclude>pom.xml.asc</exclude>
                        <exclude>jenkins/databricks/*.patch</exclude>
                        <exclude>*.jar</exclude>
                        <exclude>docs/demo/**/*.ipynb</exclude>
                        <exclude>docs/demo/**/*.zpln</exclude>
                        <exclude>**/src/main/resources/META-INF/services/*</exclude>
                        <exclude>**/src/test/resources/**</exclude>
                        <exclude>rmm_log.txt</exclude>
                        <exclude>dependency-reduced-pom.xml</exclude>
                        <exclude>**/.*/**</exclude>
                        <exclude>src/main/java/com/nvidia/spark/rapids/format/*</exclude>
                        <exclude>**/*.csv</exclude>
                        <!-- Apache Rat excludes target folder for projects that are included by
                        default, but there are some projects that are conditionally included.  -->
                        <exclude>**/target/**/*</exclude>
                    </excludes>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-antrun-plugin</artifactId>
                <executions>
                    <execution>
                        <phase>generate-resources</phase>
                        <configuration>
                            <!-- Execute the shell script to generate the plugin build information. -->
                            <target>
                                <mkdir dir="${project.build.directory}/extra-resources"/>
                                <mkdir dir="${project.build.directory}/tmp"/>
                                <exec executable="bash" failonerror="true" output="${project.build.directory}/extra-resources/rapids4spark-version-info.properties">
                                    <arg value="${user.dir}/build/build-info"/>
                                    <arg value="${project.version}"/>
                                    <arg value="${cudf.version}"/>
                                </exec>
                            </target>
                        </configuration>
                        <goals>
                            <goal>run</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.jacoco</groupId>
                <artifactId>jacoco-maven-plugin</artifactId>
                <executions>
                    <execution>
                        <id>prepare-agent</id>
                        <goals>
                            <goal>prepare-agent</goal>
                        </goals>
                        <configuration>
                            <append>true</append>
                            <excludes>
                                <exclude>${rapids.shade.package}.*</exclude>
                            </excludes>
                            <includes>
                                <include>ai.rapids.cudf.*</include>
                                <include>com.nvidia.spark.*</include>
                                <include>org.apache.spark.sql.rapids.*</include>
                            </includes>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
    <repositories>
        <repository>
            <id>snapshots-repo</id>
            <url>https://oss.sonatype.org/content/repositories/snapshots</url>
            <releases>
                <enabled>false</enabled>
            </releases>
            <snapshots>
                <enabled>true</enabled>
            </snapshots>
        </repository>
        <repository>
            <id>apache-snapshots-repo</id>
            <url>https://repository.apache.org/content/repositories/snapshots/</url>
            <releases>
                <enabled>false</enabled>
            </releases>
            <snapshots>
                <enabled>true</enabled>
            </snapshots>
        </repository>
        <repository>
            <id>cloudera-repo</id>
            <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
        </repository>
    </repositories>
</project>
