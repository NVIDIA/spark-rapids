<?xml version="1.0" encoding="UTF-8"?>
<!--
  Copyright (c) 2020-2022, NVIDIA CORPORATION.

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>com.nvidia</groupId>
        <artifactId>rapids-4-spark-parent</artifactId>
        <version>22.04.0-SNAPSHOT</version>
    </parent>
    <artifactId>rapids-4-spark-udf_2.12</artifactId>
    <name>RAPIDS Accelerator for Apache Spark Scala UDF Plugin</name>
    <description>The RAPIDS Scala UDF plugin for Apache Spark</description>
    <version>22.04.0-SNAPSHOT</version>

    <dependencies>
        <dependency>
            <groupId>ai.rapids</groupId>
            <artifactId>cudf</artifactId>
            <classifier>${cuda.version}</classifier>
        </dependency>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.binary.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_${scala.binary.version}</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>com.nvidia</groupId>
            <artifactId>rapids-4-spark-sql_${scala.binary.version}</artifactId>
            <version>${project.version}</version>
            <classifier>${spark.version.classifier}</classifier>
            <scope>provided</scope>
        </dependency>
    </dependencies>

    <profiles>
       <profile>
           <!--
                 Note that we are using the Spark version for all of the Databricks dependencies as well.
                 The jenkins/databricks/build.sh script handles installing the jars as maven artifacts.
                 This is to make it easier and not have to change version numbers for each individual dependency
                 and deal with differences between Databricks versions
            -->
            <id>dbdeps</id>
            <activation>
                <property>
                    <name>databricks</name>
                </property>
            </activation>
            <dependencies>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-sql_${scala.binary.version}</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-core_${scala.binary.version}</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-annotation_${scala.binary.version}</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.javaassist</groupId>
                    <artifactId>javaassist</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.json4s</groupId>
                    <artifactId>JsonAST</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-unsafe_${scala.binary.version}</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-catalyst_${scala.binary.version}</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
           </dependencies>
       </profile>
       <profile>
            <id>release311cdh</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>311cdh</value>
                </property>
            </activation>
            <dependencies>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-sql_${scala.binary.version}</artifactId>
                    <version>${spark311cdh.version}</version>
                    <exclusions>
                        <exclusion>
                            <groupId>org.apache.curator</groupId>
                            <artifactId>curator-recipes</artifactId>
                        </exclusion>
                    </exclusions>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-hive_${scala.binary.version}</artifactId>
                    <version>${spark311cdh.version}</version>
                    <exclusions>
                        <exclusion>
                            <groupId>org.apache.spark</groupId>
                            <artifactId>spark-core_${scala.binary.version}</artifactId>
                        </exclusion>
                    </exclusions>
                </dependency>
                <dependency>
                    <groupId>org.apache.curator</groupId>
                    <artifactId>curator-recipes</artifactId>
                    <version>4.3.0.7.2.7.0-184</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <!-- it seems CDH jars pull an old version of Guava but need new version
                         to run with, so here we override Guava version for testing -->
                    <groupId>com.google.guava</groupId>
                    <artifactId>guava</artifactId>
                    <version>${guava.cdh.version}</version>
                    <scope>test</scope>
                </dependency>
            </dependencies>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-jar-plugin</artifactId>
                        <configuration>
                            <archive>
                                <!-- transient jar, writing compressed can take several x time -->
                                <compress>false</compress>
                            </archive>
                            <classifier>${spark.version.classifier}</classifier>
                        </configuration>
                    </plugin>
                </plugins>
            </build>
        </profile>
    </profiles>

    <build>
        <resources>
            <resource>
                <!-- Include the properties file to provide the build information. -->
                <directory>${project.build.directory}/extra-resources</directory>
                <filtering>true</filtering>
            </resource>
            <resource>
                <directory>${project.basedir}/..</directory>
                <targetPath>META-INF</targetPath>
                <includes>
                    <!-- The NOTICE will be taken care of by the antrun task below -->
                    <include>LICENSE</include>
                </includes>
            </resource>
        </resources>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <configuration>
                    <archive>
                        <!-- transient jar, writing compressed can take several x time -->
                        <compress>false</compress>
                    </archive>
                    <classifier>${spark.version.classifier}</classifier>
                </configuration>
            </plugin>
            <plugin>
                <artifactId>maven-antrun-plugin</artifactId>
                <executions>
                    <execution>
                        <id>copy-notice</id>
                        <goals>
                            <goal>run</goal>
                        </goals>
                        <phase>process-resources</phase>
                        <configuration>
                            <target>
                                <!-- copy NOTICE-binary to NOTICE -->
                                <copy
                                    todir="${project.build.directory}/classes/META-INF/"
                                    verbose="true">
                                    <fileset dir="${project.basedir}/..">
                                        <include name="NOTICE-binary"/>
                                    </fileset>
                                    <mapper type="glob" from="*-binary" to="*"/>
                                </copy>
                            </target>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <!-- disable surefire as we are using scalatest only -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <configuration>
                    <skipTests>true</skipTests>
                </configuration>
            </plugin>
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>org.scalatest</groupId>
                <artifactId>scalatest-maven-plugin</artifactId>
            </plugin>
        </plugins>
    </build>
</project>
