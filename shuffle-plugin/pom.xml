<?xml version="1.0" encoding="UTF-8"?>
<!--
  Copyright (c) 2020-2022, NVIDIA CORPORATION.

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>com.nvidia</groupId>
        <artifactId>rapids-4-spark-parent</artifactId>
        <version>22.04.0-SNAPSHOT</version>
    </parent>

    <artifactId>rapids-4-spark-shuffle_2.12</artifactId>
    <name>RAPIDS Accelerator for Apache Spark Shuffle Plugin</name>
    <description>Accelerated shuffle plugin for the RAPIDS plugin for Apache Spark</description>
    <version>22.04.0-SNAPSHOT</version>

    <dependencies>
        <dependency>
            <groupId>ai.rapids</groupId>
            <artifactId>cudf</artifactId>
            <classifier>${cuda.version}</classifier>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
        </dependency>
        <dependency>
          <groupId>org.openucx</groupId>
          <artifactId>jucx</artifactId>
          <version>1.11</version>
          <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>com.nvidia</groupId>
            <artifactId>rapids-4-spark-common_${scala.binary.version}</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>com.nvidia</groupId>
            <artifactId>rapids-4-spark-sql_${scala.binary.version}</artifactId>
            <version>${project.version}</version>
            <classifier>${spark.version.classifier}</classifier>
            <scope>provided</scope>
        </dependency>
    </dependencies>

    <profiles>
        <profile>
            <id>with-classifier</id>
            <activation>
                <activeByDefault>true</activeByDefault>
            </activation>
            <dependencies>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-sql_${scala.binary.version}</artifactId>
                </dependency>
            </dependencies>
        </profile>
        <profile>
            <id>release311cdh</id>
            <activation>
                <property>
                    <name>buildver</name>
                    <value>311cdh</value>
                </property>
            </activation>
            <dependencies>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-sql_${scala.binary.version}</artifactId>
                    <version>${spark311cdh.version}</version>
                    <exclusions>
                        <exclusion>
                            <groupId>org.apache.curator</groupId>
                            <artifactId>curator-recipes</artifactId>
                        </exclusion>
                    </exclusions>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.apache.curator</groupId>
                    <artifactId>curator-recipes</artifactId>
                    <version>4.3.0.7.2.7.0-184</version>
                    <scope>provided</scope>
                </dependency>
            </dependencies>
        </profile>
       <profile>
            <!--
                 Note that we are using the Spark version for all of the Databricks dependencies as well.
                 The jenkins/databricks/build.sh script handles installing the jars as maven artifacts.
                 This is to make it easier and not have to change version numbers for each individual dependency
                 and deal with differences between Databricks versions
            -->
            <id>dbdeps</id>
            <activation>
                <property>
                    <name>databricks</name>
                </property>
            </activation>
            <dependencies>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-sql_${scala.binary.version}</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-core_${scala.binary.version}</artifactId>
                    <version>${spark.version}</version>
                    <scope>provided</scope>
                </dependency>
            </dependencies>
        </profile>
    </profiles>

    <build>
        <resources>
          <resource>
            <!-- Include the properties file to provide the build information. -->
            <directory>${project.build.directory}/extra-resources</directory>
            <filtering>true</filtering>
          </resource>
          <resource>
            <directory>${project.basedir}/..</directory>
            <targetPath>META-INF</targetPath>
            <includes>
              <!-- The NOTICE will be taken care of by the antrun task below -->
              <include>LICENSE</include>
            </includes>
          </resource>
        </resources>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <configuration>
                    <archive>
                        <!-- transient jar, writing compressed can take several x time -->
                        <compress>false</compress>
                    </archive>
                    <classifier>${spark.version.classifier}</classifier>
                </configuration>
            </plugin>
            <plugin>
              <artifactId>maven-antrun-plugin</artifactId>
              <executions>
                <execution>
                  <id>copy-notice</id>
                  <goals>
                    <goal>run</goal>
                  </goals>
                  <phase>process-resources</phase>
                  <configuration>
                    <target>
                      <!-- copy NOTICE-binary to NOTICE -->
                      <copy
                          todir="${project.build.directory}/classes/META-INF/"
                          verbose="true">
                        <fileset dir="${project.basedir}/..">
                          <include name="NOTICE-binary"/>
                        </fileset>
                        <mapper type="glob" from="*-binary" to="*"/>
                      </copy>
                    </target>
                  </configuration>
                </execution>
              </executions>
            </plugin>
            <!-- disable surefire as tests are some place else -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <configuration>
                    <skipTests>true</skipTests>
                </configuration>
            </plugin>
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>org.apache.rat</groupId>
                <artifactId>apache-rat-plugin</artifactId>
            </plugin>
        </plugins>
    </build>
</project>
